{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92df4438-f89c-4874-8951-a0f19195c7c8",
   "metadata": {},
   "source": [
    "# contrastive learning on two seperate modalities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5295f4b9-c562-41cf-bc1e-422e4a82202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_LAUNCH_BLOCKING\"] = \"1\"\n",
    "os.environ['TENSORBOARD_BINARY'] = '/p/project1/hai_fzj_bda/koenig8/jupyter/kernels/contrastive_learn/bin/tensorboard'\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n",
    "from torch.optim import SGD, Adam\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "import scanpy as sc\n",
    "from pytorch_lightning.callbacks import TQDMProgressBar\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1c2475db-dd2c-4ca4-a23a-a0a3441cb897",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleModel(nn.Module):\n",
    "   def __init__(self, out_dim = 512, in_dim=512, hidden_dim = 512):\n",
    "       super().__init__()\n",
    "\n",
    "       # add mlp projection head\n",
    "       self.model = nn.Sequential(\n",
    "           nn.Linear(in_features=in_dim, out_features=hidden_dim),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(in_features=hidden_dim, out_features=out_dim)\n",
    "       )\n",
    "\n",
    "   def forward(self, x):\n",
    "       return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4d0d5d32-e428-420b-a1fd-9ff0205d87c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(pl.LightningModule):\n",
    "   \"\"\"\n",
    "   Vanilla Contrastive loss, also called InfoNceLoss as in SimCLR paper\n",
    "   \"\"\"\n",
    "   def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=500, log_every = 2000, histo_size = 368, st_size = 50):\n",
    "       super().__init__()\n",
    "       self.save_hyperparameters()\n",
    "       assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "       self.histo_model = SimpleModel(in_dim = histo_size, hidden_dim = hidden_dim, out_dim = 4 * hidden_dim)\n",
    "       self.st_model = SimpleModel(in_dim = st_size, hidden_dim = hidden_dim, out_dim = 4 * hidden_dim)\n",
    "       self.log_every = log_every\n",
    "\n",
    "   def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer,\n",
    "                                                            T_max=self.hparams.max_epochs,\n",
    "                                                            eta_min=self.hparams.lr/50)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "   def info_nce_loss(self, batch, batch_idx, mode = \"train\"):\n",
    "        X_st = batch['a_batch']\n",
    "        classes_st = batch['a_is_positive']\n",
    "        X_histo = batch['b_batch']\n",
    "        classes_histo = batch['b_is_positive']\n",
    "       \n",
    "        X_st = F.normalize(X_st, p=2, dim=1)\n",
    "        X_histo = F.normalize(X_histo, p=2, dim=1)\n",
    "        emb_histo = self.histo_model(X_histo)\n",
    "        emb_st = self.st_model(X_st)\n",
    "       \n",
    "        # Index the embeddings\n",
    "        pos_st = emb_st[classes_st]\n",
    "        pos_histo = emb_histo[classes_histo]\n",
    "        neg_st = emb_st[~classes_st]\n",
    "        neg_histo = emb_histo[~classes_histo]\n",
    "        \n",
    "        # Concatenate positives and negatives\n",
    "        positives = torch.cat([pos_st, pos_histo], dim=0)\n",
    "        negatives = torch.cat([neg_st, neg_histo], dim=0)\n",
    "       \n",
    "        nce_parts = []\n",
    "        similarities = []\n",
    "        features = ((positives, positives), (positives, negatives))\n",
    "        for i in range(2):\n",
    "            # Repeat for positives and negatives\n",
    "            feat1, feat2 = features[i]\n",
    "            \n",
    "            cos_sim = F.cosine_similarity(feat1[:,None,:], feat2[None,:,:], dim=-1)\n",
    "            if i == 0:\n",
    "                # Remove the diagonal from positive to positive comparison\n",
    "                self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "                cos_sim.masked_fill_(self_mask, -9e15)\n",
    "            cos_sim = cos_sim / self.hparams.temperature\n",
    "            \n",
    "            nce_parts.append(torch.logsumexp(cos_sim, dim=-1))\n",
    "            similarities.append(cos_sim)\n",
    "            \n",
    "        nll = -nce_parts[0] + nce_parts[1]\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode+'_loss', nll)\n",
    "        # print(similarities[0].shape, similarities[1].shape)  => 60,60 and 60,240 \n",
    "        # More in depth logging (less frequent)\n",
    "        if mode == \"val\" or (batch_idx % self.log_every == 0):\n",
    "            n_pos = positives.shape[0]\n",
    "            n_neg = negatives.shape[0]\n",
    "            comb_sim = torch.cat([\n",
    "                similarities[0].sum(dim = 1) / (n_pos - 1),  # Mean cosine distance of positive samples\n",
    "                similarities[1].mean(dim = 0)  # Again fot negative samples\n",
    "            ], dim = -1)\n",
    "            sim_argsort = comb_sim.argsort(dim=-1, descending=False) \n",
    "            classes = torch.cat([torch.ones(n_pos), torch.zeros(n_neg)], dim = -1).to(sim_argsort.device)\n",
    "\n",
    "            assert sim_argsort.max() < len(classes)\n",
    "            top_classes = classes[sim_argsort] \n",
    "            self.log(mode+'_acc_top1', top_classes[0].float())\n",
    "            self.log(mode+'_acc_top5', top_classes[:5].float().mean())\n",
    "            self.log(mode+'_acc_mean_pos', top_classes[:n_pos].float().mean())\n",
    "            \n",
    "        return nll\n",
    "\n",
    "   def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, batch_idx, mode='train')\n",
    "\n",
    "   def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, batch_idx, mode='val')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5fcc750-3e55-44a9-8924-4e0682cd79cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.7941, 0.9009, 0.8743, 0.9450])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feat1 = torch.Tensor(np.array([(1000,9000,3000) , (1,2,3), (1,5,3), (5,6,7)]))\n",
    "feat2 = torch.Tensor(np.array([(1,2,3) , (2000,2000,1000)]))\n",
    "comb_sim = F.cosine_similarity(feat1[:,None,:], feat2[None,:,:], dim=-1).mean(axis = 1)\n",
    "comb_sim#.argsort(dim=-1, descending=True)#.argmin(dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2963aef6-fb8a-4dfc-9c03-18a979826495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 0., 1., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_argsort = comb_sim.argsort(dim=-1, descending=False) \n",
    "classes = torch.cat([torch.ones(2), torch.zeros(2)], dim = -1)\n",
    "classes[sim_argsort]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "29d372fa-22c0-4c42-9f23-ccb328297fbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ True, False, False, False, False, False, False, False, False, False],\n",
       "        [False,  True, False, False, False, False, False, False, False, False],\n",
       "        [False, False,  True, False, False, False, False, False, False, False],\n",
       "        [False, False, False,  True, False, False, False, False, False, False],\n",
       "        [False, False, False, False,  True, False, False, False, False, False],\n",
       "        [False, False, False, False, False,  True, False, False, False, False],\n",
       "        [False, False, False, False, False, False,  True, False, False, False],\n",
       "        [False, False, False, False, False, False, False,  True, False, False],\n",
       "        [False, False, False, False, False, False, False, False,  True, False],\n",
       "        [False, False, False, False, False, False, False, False, False,  True]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(10, dtype=torch.bool)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02d92f67-1c88-417a-a84b-2d251501718f",
   "metadata": {},
   "source": [
    "# Dataset\n",
    "From ChatGPT: precomputing indices is totally fine — especially if you have a lot of data. You're trading variance for speed and consistency, and with large enough datasets, that’s often a win. \n",
    "But if it is not diverse enough, i can look into reshuffling data every k epochs or doing dynamic sampling or including multiple samples per anchor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b41a1d4-9091-44bc-9025-9d4913b57fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PairedContrastiveDataset(Dataset):\n",
    "    def __init__(self, embeddings_a, labels_a, embeddings_b, labels_b, n_pos=1, n_neg=1, seed=42):\n",
    "        \"\"\"\n",
    "        embeddings_a: Tensor [N, D] for modality A (e.g. ST)\n",
    "        labels_a: Tensor [N] with integer class labels\n",
    "        embeddings_b: Tensor [M, D] for modality B (e.g. histo)\n",
    "        labels_b: Tensor [M] with integer class labels\n",
    "        n_pos: number of positive samples to draw per anchor\n",
    "        n_neg: number of negative samples to draw per anchor\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Convert to tensors\n",
    "        self.emb_a = torch.tensor(embeddings_a, dtype = torch.float32)\n",
    "        self.labels_a = torch.tensor(labels_a, dtype = torch.int32)\n",
    "        self.emb_b =torch.tensor(embeddings_b, dtype = torch.float32)\n",
    "        self.labels_b = torch.tensor(labels_b, dtype = torch.int32)\n",
    "        self.n_pos = n_pos\n",
    "        self.n_neg = n_neg\n",
    "        self.rng = random.Random(seed)\n",
    "\n",
    "        assert len(self.emb_a) == len(self.labels_a)\n",
    "        assert len(self.emb_b) == len(self.labels_b)\n",
    "\n",
    "        self.data = []  # List of dicts with precomputed sample indices\n",
    "\n",
    "        # Build class index lookup\n",
    "        self.class_to_indices_a = defaultdict(list)\n",
    "        self.class_to_indices_b = defaultdict(list)\n",
    "        for i, label in enumerate(labels_a.tolist()):\n",
    "            self.class_to_indices_a[label].append(i)\n",
    "        for i, label in enumerate(labels_b.tolist()):\n",
    "            self.class_to_indices_b[label].append(i)\n",
    "\n",
    "        all_labels = sorted(set(labels_a.tolist()) | set(labels_b.tolist()))\n",
    "\n",
    "        # Precompute samples for each item in modality A\n",
    "        for anchor_idx in range(len(self.emb_a)):\n",
    "            anchor_label = labels_a[anchor_idx].item()\n",
    "            self.data.append(self._make_sample(\n",
    "                anchor_idx=anchor_idx,\n",
    "                anchor_mod='a',\n",
    "                anchor_label=anchor_label\n",
    "            ))\n",
    "\n",
    "        # Precompute samples for each item in modality B\n",
    "        for anchor_idx in range(len(self.emb_b)):\n",
    "            anchor_label = labels_b[anchor_idx].item()\n",
    "            self.data.append(self._make_sample(\n",
    "                anchor_idx=anchor_idx,\n",
    "                anchor_mod='b',\n",
    "                anchor_label=anchor_label\n",
    "            ))\n",
    "\n",
    "    def _make_sample(self, anchor_idx, anchor_mod, anchor_label):\n",
    "        # Determine anchor embedding source\n",
    "        if anchor_mod == 'a':\n",
    "            same_class_to_indices = self.class_to_indices_a\n",
    "            other_class_to_indices = self.class_to_indices_b\n",
    "        else:\n",
    "            same_class_to_indices = self.class_to_indices_b\n",
    "            other_class_to_indices = self.class_to_indices_a\n",
    "\n",
    "        # Positive samples from same modality (excluding anchor)\n",
    "        pos_same_mod = [\n",
    "            idx for idx in same_class_to_indices[anchor_label]\n",
    "            if idx != anchor_idx\n",
    "        ]\n",
    "        pos_same = random.sample(pos_same_mod, min(self.n_pos - 1, len(pos_same_mod)))\n",
    "\n",
    "        # Negative samples from same modality\n",
    "        neg_same = []\n",
    "        for label, indices in same_class_to_indices.items():\n",
    "            if label != anchor_label:\n",
    "                neg_same.extend(indices)\n",
    "        neg_same = random.sample(neg_same, min(self.n_neg, len(neg_same)))\n",
    "\n",
    "        # Positive samples from other modality\n",
    "        pos_other = random.sample(other_class_to_indices[anchor_label],\n",
    "                                  min(self.n_pos, len(other_class_to_indices[anchor_label])))\n",
    "\n",
    "        # Negative samples from other modality\n",
    "        neg_other = []\n",
    "        for label, indices in other_class_to_indices.items():\n",
    "            if label != anchor_label:\n",
    "                neg_other.extend(indices)\n",
    "        neg_other = random.sample(neg_other, min(self.n_neg, len(neg_other)))\n",
    "\n",
    "        return {\n",
    "            'anchor_mod': anchor_mod,\n",
    "            'anchor_idx': anchor_idx,\n",
    "            'pos_same': pos_same,\n",
    "            'neg_same': neg_same,\n",
    "            'pos_other': pos_other,\n",
    "            'neg_other': neg_other\n",
    "        }\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        # Boolean masks: 1 for positive, 0 for negative\n",
    "        same_mod_is_positive = torch.tensor(\n",
    "            [1] * (len(sample['pos_same']) + 1) + [0] * len(sample['neg_same']), dtype=torch.bool\n",
    "        )\n",
    "        other_mod_is_positive = torch.tensor(\n",
    "            [1] * len(sample['pos_other']) + [0] * len(sample['neg_other']), dtype=torch.bool\n",
    "        )\n",
    "\n",
    "        if sample['anchor_mod'] == 'a':\n",
    "            anchor = [sample['anchor_idx'], ]\n",
    "            a_batch = torch.stack([self.emb_a[i] for i in sample['pos_same'] + anchor + sample['neg_same'] ])\n",
    "            b_batch = torch.stack([self.emb_b[i] for i in sample['pos_other'] + sample['neg_other']])\n",
    "            a_is_positive = same_mod_is_positive\n",
    "            b_is_positive = other_mod_is_positive\n",
    "        else:\n",
    "            anchor = [sample['anchor_idx'],]\n",
    "            b_batch = torch.stack([self.emb_b[i] for i in sample['pos_same'] + anchor + sample['neg_same']])\n",
    "            a_batch = torch.stack([self.emb_a[i] for i in sample['pos_other'] + sample['neg_other']])  \n",
    "            b_is_positive = same_mod_is_positive\n",
    "            a_is_positive = other_mod_is_positive\n",
    "\n",
    "        return {\n",
    "            'a_batch': a_batch,\n",
    "            'a_is_positive': a_is_positive,\n",
    "            'b_batch': b_batch,\n",
    "            'b_is_positive': b_is_positive,\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1349a1c-99b8-4453-8f1d-569194dedfc2",
   "metadata": {},
   "source": [
    "### Load the data and prepare it for pytorch lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2759b54a-7639-4763-950e-d078b9c4cb18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(AnnData object with n_obs × n_vars = 50000 × 50\n",
       "     obs: 'patch_id', 'brain_area', 'patchsize', 'x_st', 'y_st', 'z_st', 'brain_section_label', 'section'\n",
       "     uns: 'neighbors', 'umap'\n",
       "     obsm: 'X_umap', 'brain_area_onehot', 'brain_area_similarities', 'pca_embedding', 'pca_plus_slides', 'pca_plus_slides_scaled'\n",
       "     obsp: 'connectivities', 'distances',\n",
       " AnnData object with n_obs × n_vars = 190659 × 1536\n",
       "     obs: 'image_id', 'patchsize', 'center_ccf', 'pixel_coord', 'distance', 'nearest_ST', 'nearest_cell_id', 'target_atlas_plate', 'distance_new', 'x', 'y', 'z', 'x_st', 'y_st', 'z_st', 'image_nr', 'brain_area', 'group', 'slice', 'in_sample'\n",
       "     obsm: 'brain_area_onehot', 'brain_area_similarities', 'uni_embedding', 'uni_pca_95', 'uni_pca_plus_coords')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = \"/p/project1/hai_fzj_bda/koenig8/ot/data/\"\n",
    "adata_st = sc.read_h5ad(os.path.join(path, \"adata_st.h5ad\"))\n",
    "adata_histo = sc.read_h5ad(os.path.join(path, \"adata_histo.h5ad\"))\n",
    "adata_st, adata_histo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "813914b6-b101-4a71-9bdd-0882e0274e15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 5,  5,  5, ..., 18,  5,  5])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adata_st.obsm[\"brain_area_onehot\"].toarray().nonzero()[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97f7e055-4f7f-4bbe-a982-2edec2afd4fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation slides ['Zhuang-ABCA-1.079', 'Zhuang-ABCA-1.089', 'Zhuang-ABCA-1.085', 'Zhuang-ABCA-1.077', 'Zhuang-ABCA-1.087', 'Zhuang-ABCA-1.049', 'Zhuang-ABCA-1.059', 'Zhuang-ABCA-1.069', 'Zhuang-ABCA-1.072', 'Zhuang-ABCA-1.082']\n"
     ]
    }
   ],
   "source": [
    "embeddings_a=adata_st.obsm[\"pca_embedding\"]\n",
    "labels_a=adata_st.obsm[\"brain_area_onehot\"].toarray().nonzero()[-1]\n",
    "embeddings_b=adata_histo.obsm[\"uni_pca_95\"]\n",
    "labels_b=adata_histo.obsm[\"brain_area_onehot\"].toarray().nonzero()[-1]\n",
    "seed = 42\n",
    "\n",
    "# For st, exclude 10 slides from the train set\n",
    "val_slides = list(adata_st.obs[\"brain_section_label\"].unique()[:10])\n",
    "print(\"Validation slides\", val_slides)\n",
    "st_cond = adata_st.obs[\"brain_section_label\"].isin(val_slides).to_numpy()\n",
    "\n",
    "# For histo, exclude 20% of the train set\n",
    "rng = np.random.default_rng(seed=seed) \n",
    "sample_size = int(embeddings_b.shape[0] / 5)\n",
    "sample = rng.choice(embeddings_b.shape[0], size=sample_size, replace=False)\n",
    "histo_cond = np.zeros(shape=(embeddings_b.shape[0]), dtype = bool)\n",
    "histo_cond[sample] = True\n",
    "\n",
    "def make_set(n_pos, n_neg, random_seed, mode = \"train\"):\n",
    "    if mode == \"train\":\n",
    "        _st_cond = ~st_cond\n",
    "        _histo_cond = ~histo_cond\n",
    "    elif mode == \"val\": \n",
    "        _st_cond = st_cond\n",
    "        _histo_cond = histo_cond\n",
    "    return PairedContrastiveDataset(\n",
    "        embeddings_a=embeddings_a[_st_cond], \n",
    "        labels_a=labels_a[_st_cond], \n",
    "        embeddings_b=embeddings_b[_histo_cond], \n",
    "        labels_b=labels_b[_histo_cond], \n",
    "        n_pos=n_pos,\n",
    "        n_neg=n_neg,\n",
    "        seed=random_seed\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02ee8af0-0af1-48d6-932e-0bb4f9bd529f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(197302, 43357)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset = make_set(\n",
    "    n_pos=30,\n",
    "    n_neg=120,\n",
    "    random_seed=seed, mode = \"train\"\n",
    ")\n",
    "val_dataset = make_set(\n",
    "    n_pos=30,\n",
    "    n_neg=120,\n",
    "    random_seed=seed, mode = \"val\"\n",
    ")\n",
    "len(train_dataset), len(val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1850fe4-48f5-467a-9f2c-de20077b115f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([150, 50]),\n",
       " torch.Size([150]),\n",
       " torch.Size([150, 368]),\n",
       " torch.Size([150])]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.shape for  _, x in train_dataset[0].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eb5db5ff-ecf0-4797-a450-c2e2b94e34f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a_batch', 'a_is_positive', 'b_batch', 'b_is_positive']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x for  x,_ in train_dataset[0].items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c18dd505-7fa1-4d0d-b534-9aa0aa15d4db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['a_batch', 'a_is_positive', 'b_batch', 'b_is_positive'])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_dataset[0].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f747712c-b371-418c-8d18-0556775a40dc",
   "metadata": {},
   "source": [
    "==> This works nicely to fetch data, but takes quite long to build the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3eb93263-5d27-455a-ab18-9395c3d72cc0",
   "metadata": {},
   "source": [
    "## Use the dataloader with the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bb0b540-9bd0-4bc1-9c04-5e23778abf17",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[rank: 0] Global seed set to 42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda:0\n",
      "Number of workers: 72\n"
     ]
    }
   ],
   "source": [
    "CHECKPOINT_PATH = \"/p/project1/hai_fzj_bda/koenig8/cl/simple_model\"\n",
    "NUM_WORKERS = int(os.cpu_count() * 0.75)  # Reserve some workers\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "# Setting the seed\n",
    "pl.seed_everything(42)\n",
    "\n",
    "# Ensure that all operations are deterministic on GPU (if used) for reproducibility\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "\n",
    "device = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "print(\"Device:\", device)\n",
    "print(\"Number of workers:\", NUM_WORKERS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf5752ee-fff1-4a34-a618-6d0e846297b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ERROR: Could not find '/p/project1/hai_fzj_bda/koenig8/jupyter/kernels\n",
       "/contrastive_learn/bin/tensorboard' (set by the `TENSORBOARD_BINARY`\n",
       "environment variable). Please ensure that your PATH contains an\n",
       "executable `tensorboard` program, or explicitly specify the path to a\n",
       "TensorBoard binary by setting the `TENSORBOARD_BINARY` environment\n",
       "variable."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "15eafa0b-b145-4131-80ea-822189837d28",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_simclr(max_epochs=500, **kwargs):\n",
    "    progress_bar = TQDMProgressBar(refresh_rate=2000)\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, 'SimCLR'),\n",
    "                         accelerator=\"gpu\" if str(device).startswith(\"cuda\") else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=max_epochs,\n",
    "                         limit_train_batches=0.2,  # To only use 20% each epoch\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc_top5'),\n",
    "                                    LearningRateMonitor('epoch'), progress_bar])\n",
    "    trainer.logger._default_hp_metric = None # Optional logging argument that we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, 'SimCLR.ckpt')\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f'Found pretrained model at {pretrained_filename}, loading...')\n",
    "        model = SimCLR.load_from_checkpoint(pretrained_filename) # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=1, shuffle=True,\n",
    "                                       pin_memory=True, num_workers=NUM_WORKERS)\n",
    "        val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=1, shuffle=False,\n",
    "                                     pin_memory=True, num_workers=NUM_WORKERS)\n",
    "        pl.seed_everything(42) # To be reproducable\n",
    "        model = SimCLR(max_epochs=max_epochs, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path) # Load best checkpoint after training\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ef6adf-4838-48e1-a6e2-da7b5cbef16b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "[rank: 0] Global seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1,2,3     ]\n",
      "\n",
      "  | Name        | Type        | Params\n",
      "--------------------------------------------\n",
      "0 | histo_model | SimpleModel | 113 K \n",
      "1 | st_model    | SimpleModel | 72.6 K\n",
      "--------------------------------------------\n",
      "185 K     Trainable params\n",
      "0         Non-trainable params\n",
      "185 K     Total params\n",
      "0.743     Total estimated model params size (MB)\n",
      "SLURM auto-requeueing enabled. Setting signal handlers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0:  46%|████▌     | 38000/82817 [06:47<08:00, 93.24it/s, loss=-8.24, v_num=1.13e+7]"
     ]
    }
   ],
   "source": [
    "simclr_model = train_simclr(hidden_dim=128,\n",
    "                            lr=5e-4,\n",
    "                            temperature=0.07,\n",
    "                            weight_decay=1e-4,\n",
    "                            max_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a19eed-cd44-4d2a-9470-5014f8a01227",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "contrastive_learn",
   "language": "python",
   "name": "contrastive_learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
